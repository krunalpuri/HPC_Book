\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Jha2014}
\citation{Jha2014}
\select@language{american}
\@writefile{toc}{\select@language{american}}
\@writefile{lof}{\select@language{american}}
\@writefile{lot}{\select@language{american}}
\@writefile{toc}{\contentsline {title}{Big Data with High Performance Computing (HPC)}{1}{chapter.1}}
\@writefile{toc}{\authcount {3}}
\@writefile{toc}{\contentsline {author}{Tarek El-Ghazawi \and Krunal Puri \and Armin Mehrabian}{1}{chapter.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1.1}}
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{1}}
\citation{braam2004lustre}
\citation{FrankSchmuck}
\citation{shaun2007storage}
\citation{rajasekar2010irods}
\citation{grimshaw2013gffs}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Matrix of data and computation applications.}}{2}{figure.1.1}}
\newlabel{fig:bigdata_hpc_matrix}{{1}{2}{Matrix of data and computation applications}{figure.1.1}{}}
\newlabel{fig:bigdata_hpc_matrix@cref}{{[figure][1][]1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}HPC Architecture}{2}{subsection.1.1.1}}
\citation{yoo2003slurm}
\citation{staples2006torque}
\citation{gentzsch2001sun}
\citation{plimpton2011mapreduce}
\citation{mantha2012pilot}
\citation{ekanayake2010twister}
\citation{luckow2012p}
\citation{raicu2008many}
\citation{deelman2009workflows}
\citation{shvachko2010hadoop}
\citation{ghemawat2003google}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Apache Big Data Stack (ABDS) ecosystem vs. High Performance Computing (HPC) ecosystem \cite  {Jha2014}.}}{3}{figure.1.2}}
\newlabel{fig:bigdata_hpc_ecosystem}{{2}{3}{Apache Big Data Stack (ABDS) ecosystem vs. High Performance Computing (HPC) ecosystem \cite {Jha2014}}{figure.1.2}{}}
\newlabel{fig:bigdata_hpc_ecosystem@cref}{{[figure][2][]2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}ABDS Architectures}{3}{subsection.1.1.2}}
\citation{vavilapalli2013apache}
\citation{borthakur2011apache}
\citation{zaharia2012resilient}
\citation{qiu2014towards}
\citation{qiu2014towards}
\@writefile{toc}{\contentsline {section}{\numberline {2}State of the art projects}{5}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Integration of HPC and Big Data stack}{5}{subsection.1.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{High Performance Big Data System (HPBDS) project \cite  {qiu2014towards}}{5}{section*.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces MIDAS and SPIDAL within HPC-ABDS stack\cite  {qiu2014towards}}}{5}{figure.1.3}}
\newlabel{fig:MIDAS_SPIDAL}{{3}{5}{MIDAS and SPIDAL within HPC-ABDS stack\cite {qiu2014towards}}{figure.1.3}{}}
\newlabel{fig:MIDAS_SPIDAL@cref}{{[figure][3][]3}{5}}
\citation{fox2014towards}
\citation{Qiu2014}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Categories of the NIST use cases.}}{6}{table.1.1}}
\newlabel{table:NIST_vs_ogres}{{1}{6}{Categories of the NIST use cases}{table.1.1}{}}
\newlabel{table:NIST_vs_ogres@cref}{{[table][1][]1}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Five programming models identified for big data HPC problems based on NIST big data use cases.}}{7}{table.1.2}}
\newlabel{table:NIST_5_Programming_model}{{2}{7}{Five programming models identified for big data HPC problems based on NIST big data use cases}{table.1.2}{}}
\newlabel{table:NIST_5_Programming_model@cref}{{[table][2][]2}{7}}
\citation{qiu2014towards}
\citation{qiu2014towards}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces MIDAS architecture digram, where lower layers provide support for the top level tools \cite  {qiu2014towards}.}}{8}{figure.1.4}}
\newlabel{fig:MIDAS_ARCH}{{4}{8}{MIDAS architecture digram, where lower layers provide support for the top level tools \cite {qiu2014towards}}{figure.1.4}{}}
\newlabel{fig:MIDAS_ARCH@cref}{{[figure][4][]4}{8}}
\citation{domo}
\citation{hinton2006fast}
\citation{domo}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Machine Learning and HPC}{9}{subsection.1.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces One minute of Internet usage \cite  {domo}.}}{9}{table.1.3}}
\newlabel{table:Domo}{{3}{9}{One minute of Internet usage \cite {domo}}{table.1.3}{}}
\newlabel{table:Domo@cref}{{[table][3][]3}{9}}
\citation{dean2012large}
\citation{dean2012large}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces Data parallelism architecture performing Stochastic Gradient Descent (SGC). Model replicas at each node calculate gradients $\Delta w $ on a piece of data. Gradients are later transmitted asynchronously to Parameter Server to calculate updated weights.}}{10}{figure.1.5}}
\newlabel{fig:data_parallelism}{{5}{10}{Data parallelism architecture performing Stochastic Gradient Descent (SGC). Model replicas at each node calculate gradients $\Delta w $ on a piece of data. Gradients are later transmitted asynchronously to Parameter Server to calculate updated weights}{figure.1.5}{}}
\newlabel{fig:data_parallelism@cref}{{[figure][5][]5}{10}}
\citation{chilimbi2014project}
\citation{le2013building}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces An example of model parallelism scheme in DistBelief framework for deep distributed neural networks by Google \cite  {dean2012large}. Model is distributed accross four machines. Only nodes, which have edges crossing from one machine to another need to report their state.}}{11}{figure.1.6}}
\newlabel{fig:model_parallelism}{{6}{11}{An example of model parallelism scheme in DistBelief framework for deep distributed neural networks by Google \cite {dean2012large}. Model is distributed accross four machines. Only nodes, which have edges crossing from one machine to another need to report their state}{figure.1.6}{}}
\newlabel{fig:model_parallelism@cref}{{[figure][6][]6}{11}}
\citation{deng2009imagenet}
\citation{farber1997parallel}
\citation{chilimbi2014project}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Model and data partitioning in Adam architecture\cite  {chilimbi2014project}.}}{12}{figure.1.7}}
\newlabel{fig:adam_parallelism}{{7}{12}{Model and data partitioning in Adam architecture\cite {chilimbi2014project}}{figure.1.7}{}}
\newlabel{fig:adam_parallelism@cref}{{[figure][7][]7}{12}}
\citation{chilimbi2014project}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Global Parameter Server architecture of Adam\cite  {chilimbi2014project}.}}{14}{figure.1.8}}
\newlabel{fig:adam_global_param}{{8}{14}{Global Parameter Server architecture of Adam\cite {chilimbi2014project}}{figure.1.8}{}}
\newlabel{fig:adam_global_param@cref}{{[figure][8][]8}{14}}
\citation{simard2003best}
\citation{goodfellow2013maxout}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Adam accuracy on MNIST benchmark compared to the existing top accuracy model.}}{15}{table.1.4}}
\newlabel{table:MNIST}{{4}{15}{Adam accuracy on MNIST benchmark compared to the existing top accuracy model}{table.1.4}{}}
\newlabel{table:MNIST@cref}{{[table][4][]4}{15}}
\citation{le2013building}
\citation{le2013building}
\citation{chen2014dadiannao}
\citation{temam2012defect}
\citation{esmaeilzadeh2012neural}
\citation{chen2014diannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Adam accuracy on ImageNet benchmark compared to the existing top accuracy model.}}{16}{table.1.5}}
\newlabel{table:ImageNet}{{5}{16}{Adam accuracy on ImageNet benchmark compared to the existing top accuracy model}{table.1.5}{}}
\newlabel{table:ImageNet@cref}{{[table][5][]5}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Block diagram of the DianNao accelerator\cite  {chen2014dadiannao}.}}{17}{figure.1.9}}
\newlabel{fig:diannao_arch}{{9}{17}{Block diagram of the DianNao accelerator\cite {chen2014dadiannao}}{figure.1.9}{}}
\newlabel{fig:diannao_arch@cref}{{[figure][9][]9}{17}}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Speedup of CPU/GPU and CPU/DianNao for various layer types of network\cite  {chen2014dadiannao}.}}{17}{figure.1.10}}
\newlabel{fig:diannao_speedup}{{10}{17}{Speedup of CPU/GPU and CPU/DianNao for various layer types of network\cite {chen2014dadiannao}}{figure.1.10}{}}
\newlabel{fig:diannao_speedup@cref}{{[figure][10][]10}{17}}
\citation{chen2014diannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Block diagram of a node within Dadiannao architecture \cite  {chen2014dadiannao}.}}{19}{figure.1.11}}
\newlabel{fig:NFU_Diagram}{{11}{19}{Block diagram of a node within Dadiannao architecture \cite {chen2014dadiannao}}{figure.1.11}{}}
\newlabel{fig:NFU_Diagram@cref}{{[figure][11][]11}{19}}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Left: Tile implementation of a node. Right: Layout of unit inside a tile. \cite  {chen2014dadiannao}.}}{19}{figure.1.12}}
\newlabel{fig:tiles}{{12}{19}{Left: Tile implementation of a node. Right: Layout of unit inside a tile. \cite {chen2014dadiannao}}{figure.1.12}{}}
\newlabel{fig:tiles@cref}{{[figure][12][]12}{19}}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Speedup of Dadiannao/GPU for various types of layers. CONV1 and fullNN layers require at least 4 nodes. CONV3* and CONV4* need at least 36 nodes to operate\cite  {chen2014dadiannao}.}}{20}{figure.1.13}}
\newlabel{fig:dadiannao_speedup}{{13}{20}{Speedup of Dadiannao/GPU for various types of layers. CONV1 and fullNN layers require at least 4 nodes. CONV3* and CONV4* need at least 36 nodes to operate\cite {chen2014dadiannao}}{figure.1.13}{}}
\newlabel{fig:dadiannao_speedup@cref}{{[figure][13][]13}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Comparison of energy reduction of Dadiannao against GPU in the training mode\cite  {chen2014dadiannao}.}}{21}{figure.1.14}}
\newlabel{fig:dadiannao_training}{{14}{21}{Comparison of energy reduction of Dadiannao against GPU in the training mode\cite {chen2014dadiannao}}{figure.1.14}{}}
\newlabel{fig:dadiannao_training@cref}{{[figure][14][]14}{21}}
\@writefile{lof}{\contentsline {figure}{\numberline {15}{\ignorespaces Comparison of energy reduction of Dadiannao against GPU in the inference mode\cite  {chen2014dadiannao}.}}{21}{figure.1.15}}
\newlabel{fig:dadiannao_inference}{{15}{21}{Comparison of energy reduction of Dadiannao against GPU in the inference mode\cite {chen2014dadiannao}}{figure.1.15}{}}
\newlabel{fig:dadiannao_inference@cref}{{[figure][15][]15}{21}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.3}Parallel Databases}{22}{subsection.1.2.3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.4}Project SCOPE}{23}{subsection.1.2.4}}
\bibstyle{splncs03}
\bibdata{paper_2.bib}
\bibcite{domo}{1}
\bibcite{}{2}
\bibcite{borthakur2011apache}{3}
\bibcite{braam2004lustre}{4}
\bibcite{chen2014diannao}{5}
\bibcite{chen2014dadiannao}{6}
\bibcite{chilimbi2014project}{7}
\bibcite{dean2012large}{8}
\bibcite{deelman2009workflows}{9}
\bibcite{deng2009imagenet}{10}
\bibcite{ekanayake2010twister}{11}
\bibcite{esmaeilzadeh2012neural}{12}
\bibcite{farber1997parallel}{13}
\bibcite{fox2014towards}{14}
\bibcite{FrankSchmuck}{15}
\bibcite{gentzsch2001sun}{16}
\bibcite{ghemawat2003google}{17}
\bibcite{goodfellow2013maxout}{18}
\bibcite{grimshaw2013gffs}{19}
\bibcite{hinton2006fast}{20}
\bibcite{Jha2014}{21}
\bibcite{kashyap2015big}{22}
\bibcite{le2013building}{23}
\bibcite{luckow2012p}{24}
\bibcite{mantha2012pilot}{25}
\bibcite{plimpton2011mapreduce}{26}
\bibcite{Qiu2014}{27}
\bibcite{qiu2014towards}{28}
\bibcite{raicu2008many}{29}
\bibcite{rajasekar2010irods}{30}
\bibcite{Reed2015}{31}
\bibcite{shaun2007storage}{32}
\bibcite{shvachko2010hadoop}{33}
\bibcite{simard2003best}{34}
\bibcite{staples2006torque}{35}
\bibcite{temam2012defect}{36}
\bibcite{vavilapalli2013apache}{37}
\bibcite{yoo2003slurm}{38}
\bibcite{zaharia2012resilient}{39}
\citation{*}
