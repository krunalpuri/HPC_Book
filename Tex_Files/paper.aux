\relax 
\providecommand\hyper@newdestlabel[2]{}
\providecommand\HyperFirstAtBeginDocument{\AtBeginDocument}
\HyperFirstAtBeginDocument{\ifx\hyper@anchor\@undefined
\global\let\oldcontentsline\contentsline
\gdef\contentsline#1#2#3#4{\oldcontentsline{#1}{#2}{#3}}
\global\let\oldnewlabel\newlabel
\gdef\newlabel#1#2{\newlabelxx{#1}#2}
\gdef\newlabelxx#1#2#3#4#5#6{\oldnewlabel{#1}{{#2}{#3}}}
\AtEndDocument{\ifx\hyper@anchor\@undefined
\let\contentsline\oldcontentsline
\let\newlabel\oldnewlabel
\fi}
\fi}
\global\let\hyper@last\relax 
\gdef\HyperFirstAtBeginDocument#1{#1}
\providecommand\HyField@AuxAddToFields[1]{}
\providecommand\HyField@AuxAddToCoFields[2]{}
\citation{Jha2014}
\citation{Jha2014}
\select@language{american}
\@writefile{toc}{\select@language{american}}
\@writefile{lof}{\select@language{american}}
\@writefile{lot}{\select@language{american}}
\@writefile{toc}{\contentsline {title}{Big Data with High Performance Computing (HPC)}{1}{chapter.1}}
\@writefile{toc}{\authcount {3}}
\@writefile{toc}{\contentsline {author}{Tarek El-Ghazawi \and Krunal Puri \and Armin Mehrabian}{1}{chapter.1}}
\@writefile{toc}{\contentsline {section}{\numberline {1}Introduction}{1}{section.1.1}}
\newlabel{sec:intro}{{1}{1}{Introduction}{section.1.1}{}}
\newlabel{sec:intro@cref}{{[section][1][]1}{1}}
\citation{braam2004lustre}
\citation{FrankSchmuck}
\citation{shaun2007storage}
\citation{rajasekar2010irods}
\citation{grimshaw2013gffs}
\@writefile{lof}{\contentsline {figure}{\numberline {1}{\ignorespaces Matrix of data and computation applications.}}{2}{figure.1.1}}
\newlabel{fig:bigdata_hpc_matrix}{{1}{2}{Matrix of data and computation applications}{figure.1.1}{}}
\newlabel{fig:bigdata_hpc_matrix@cref}{{[figure][1][]1}{2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.1}HPC Architecture}{2}{subsection.1.1.1}}
\citation{yoo2003slurm}
\citation{staples2006torque}
\citation{gentzsch2001sun}
\citation{plimpton2011mapreduce}
\citation{mantha2012pilot}
\citation{ekanayake2010twister}
\citation{luckow2012p}
\citation{raicu2008many}
\citation{deelman2009workflows}
\citation{shvachko2010hadoop}
\citation{ghemawat2003google}
\@writefile{lof}{\contentsline {figure}{\numberline {2}{\ignorespaces Apache Big Data Stack (ABDS) ecosystem vs. High Performance Computing (HPC) ecosystem \cite  {Jha2014}.}}{3}{figure.1.2}}
\newlabel{fig:bigdata_hpc_ecosystem}{{2}{3}{Apache Big Data Stack (ABDS) ecosystem vs. High Performance Computing (HPC) ecosystem \cite {Jha2014}}{figure.1.2}{}}
\newlabel{fig:bigdata_hpc_ecosystem@cref}{{[figure][2][]2}{3}}
\@writefile{toc}{\contentsline {subsection}{\numberline {1.2}ABDS Architectures}{3}{subsection.1.1.2}}
\citation{vavilapalli2013apache}
\citation{borthakur2011apache}
\citation{zaharia2012resilient}
\citation{qiu2014towards}
\citation{qiu2014towards}
\@writefile{toc}{\contentsline {section}{\numberline {2}State of the art projects}{5}{section.1.2}}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.1}Integration of HPC and Big Data stack}{5}{subsection.1.2.1}}
\@writefile{toc}{\contentsline {subsubsection}{High Performance Big Data System (HPBDS) project \cite  {qiu2014towards}}{5}{section*.2}}
\@writefile{lof}{\contentsline {figure}{\numberline {3}{\ignorespaces MIDAS and SPIDAL within HPC-ABDS stack\cite  {qiu2014towards}}}{5}{figure.1.3}}
\newlabel{fig:MIDAS_SPIDAL}{{3}{5}{MIDAS and SPIDAL within HPC-ABDS stack\cite {qiu2014towards}}{figure.1.3}{}}
\newlabel{fig:MIDAS_SPIDAL@cref}{{[figure][3][]3}{5}}
\citation{fox2014towards}
\citation{Qiu2014}
\@writefile{lot}{\contentsline {table}{\numberline {1}{\ignorespaces Categories of the NIST use cases.}}{6}{table.1.1}}
\newlabel{table:NIST_vs_ogres}{{1}{6}{Categories of the NIST use cases}{table.1.1}{}}
\newlabel{table:NIST_vs_ogres@cref}{{[table][1][]1}{6}}
\@writefile{lot}{\contentsline {table}{\numberline {2}{\ignorespaces Five programming models identified for big data HPC problems based on NIST big data use cases.}}{7}{table.1.2}}
\newlabel{table:NIST_5_Programming_model}{{2}{7}{Five programming models identified for big data HPC problems based on NIST big data use cases}{table.1.2}{}}
\newlabel{table:NIST_5_Programming_model@cref}{{[table][2][]2}{7}}
\citation{domo}
\citation{hinton2006fast}
\citation{domo}
\@writefile{toc}{\contentsline {subsection}{\numberline {2.2}Machine Learning and HPC}{8}{subsection.1.2.2}}
\@writefile{lot}{\contentsline {table}{\numberline {3}{\ignorespaces One minute of Internet usage \cite  {domo}.}}{8}{table.1.3}}
\newlabel{table:Domo}{{3}{8}{One minute of Internet usage \cite {domo}}{table.1.3}{}}
\newlabel{table:Domo@cref}{{[table][3][]3}{8}}
\citation{dean2012large}
\citation{dean2012large}
\@writefile{lof}{\contentsline {figure}{\numberline {4}{\ignorespaces Data parallelism architecture performing Stochastic Gradient Descent (SGC). Model replicas at each node calculate gradients $\Delta w $ on a piece of data. Gradients are later transmitted asynchronously to Parameter Server to calculate updated weights.}}{9}{figure.1.4}}
\newlabel{fig:data_parallelism}{{4}{9}{Data parallelism architecture performing Stochastic Gradient Descent (SGC). Model replicas at each node calculate gradients $\Delta w $ on a piece of data. Gradients are later transmitted asynchronously to Parameter Server to calculate updated weights}{figure.1.4}{}}
\newlabel{fig:data_parallelism@cref}{{[figure][4][]4}{9}}
\citation{chilimbi2014project}
\citation{le2013building}
\@writefile{lof}{\contentsline {figure}{\numberline {5}{\ignorespaces An example of model parallelism scheme in DistBelief framework for deep distributed neural networks by Google \cite  {dean2012large}. Model is distributed accross four machines. Only nodes, which have edges crossing from one machine to another need to report their state.}}{10}{figure.1.5}}
\newlabel{fig:model_parallelism}{{5}{10}{An example of model parallelism scheme in DistBelief framework for deep distributed neural networks by Google \cite {dean2012large}. Model is distributed accross four machines. Only nodes, which have edges crossing from one machine to another need to report their state}{figure.1.5}{}}
\newlabel{fig:model_parallelism@cref}{{[figure][5][]5}{10}}
\citation{deng2009imagenet}
\citation{farber1997parallel}
\citation{chilimbi2014project}
\@writefile{lof}{\contentsline {figure}{\numberline {6}{\ignorespaces Model and data partitioning in Adam architecture\cite  {chilimbi2014project}.}}{11}{figure.1.6}}
\newlabel{fig:adam_parallelism}{{6}{11}{Model and data partitioning in Adam architecture\cite {chilimbi2014project}}{figure.1.6}{}}
\newlabel{fig:adam_parallelism@cref}{{[figure][6][]6}{11}}
\citation{chilimbi2014project}
\@writefile{lof}{\contentsline {figure}{\numberline {7}{\ignorespaces Global Parameter Server architecture of Adam\cite  {chilimbi2014project}.}}{13}{figure.1.7}}
\newlabel{fig:adam_global_param}{{7}{13}{Global Parameter Server architecture of Adam\cite {chilimbi2014project}}{figure.1.7}{}}
\newlabel{fig:adam_global_param@cref}{{[figure][7][]7}{13}}
\citation{simard2003best}
\citation{goodfellow2013maxout}
\@writefile{lot}{\contentsline {table}{\numberline {4}{\ignorespaces Adam accuracy on MNIST benchmark compared to the existing top accuracy model.}}{14}{table.1.4}}
\newlabel{table:MNIST}{{4}{14}{Adam accuracy on MNIST benchmark compared to the existing top accuracy model}{table.1.4}{}}
\newlabel{table:MNIST@cref}{{[table][4][]4}{14}}
\citation{le2013building}
\citation{le2013building}
\citation{chen2014dadiannao}
\citation{temam2012defect}
\citation{esmaeilzadeh2012neural}
\citation{chen2014diannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\@writefile{lot}{\contentsline {table}{\numberline {5}{\ignorespaces Adam accuracy on ImageNet benchmark compared to the existing top accuracy model.}}{15}{table.1.5}}
\newlabel{table:ImageNet}{{5}{15}{Adam accuracy on ImageNet benchmark compared to the existing top accuracy model}{table.1.5}{}}
\newlabel{table:ImageNet@cref}{{[table][5][]5}{15}}
\@writefile{lof}{\contentsline {figure}{\numberline {8}{\ignorespaces Block diagram of the DianNao accelerator\cite  {chen2014dadiannao}.}}{16}{figure.1.8}}
\newlabel{fig:diannao_arch}{{8}{16}{Block diagram of the DianNao accelerator\cite {chen2014dadiannao}}{figure.1.8}{}}
\newlabel{fig:diannao_arch@cref}{{[figure][8][]8}{16}}
\@writefile{lof}{\contentsline {figure}{\numberline {9}{\ignorespaces Speedup of CPU/GPU and CPU/DianNao for various layer types of network\cite  {chen2014dadiannao}.}}{16}{figure.1.9}}
\newlabel{fig:diannao_speedup}{{9}{16}{Speedup of CPU/GPU and CPU/DianNao for various layer types of network\cite {chen2014dadiannao}}{figure.1.9}{}}
\newlabel{fig:diannao_speedup@cref}{{[figure][9][]9}{16}}
\citation{chen2014diannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\@writefile{lof}{\contentsline {figure}{\numberline {10}{\ignorespaces Block diagram of a node within Dadiannao architecture \cite  {chen2014dadiannao}.}}{18}{figure.1.10}}
\newlabel{fig:NFU_Diagram}{{10}{18}{Block diagram of a node within Dadiannao architecture \cite {chen2014dadiannao}}{figure.1.10}{}}
\newlabel{fig:NFU_Diagram@cref}{{[figure][10][]10}{18}}
\@writefile{lof}{\contentsline {figure}{\numberline {11}{\ignorespaces Left: Tile implementation of a node. Right: Layout of unit inside a tile. \cite  {chen2014dadiannao}.}}{18}{figure.1.11}}
\newlabel{fig:tiles}{{11}{18}{Left: Tile implementation of a node. Right: Layout of unit inside a tile. \cite {chen2014dadiannao}}{figure.1.11}{}}
\newlabel{fig:tiles@cref}{{[figure][11][]11}{18}}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\citation{chen2014dadiannao}
\@writefile{lof}{\contentsline {figure}{\numberline {12}{\ignorespaces Speedup of Dadiannao/GPU for various types of layers. CONV1 and fullNN layers require at least 4 nodes. CONV3* and CONV4* need at least 36 nodes to operate\cite  {chen2014dadiannao}.}}{19}{figure.1.12}}
\newlabel{fig:dadiannao_speedup}{{12}{19}{Speedup of Dadiannao/GPU for various types of layers. CONV1 and fullNN layers require at least 4 nodes. CONV3* and CONV4* need at least 36 nodes to operate\cite {chen2014dadiannao}}{figure.1.12}{}}
\newlabel{fig:dadiannao_speedup@cref}{{[figure][12][]12}{19}}
\bibstyle{splncs03}
\bibdata{paper_2.bib}
\@writefile{lof}{\contentsline {figure}{\numberline {13}{\ignorespaces Comparison of energy reduction of Dadiannao against GPU in the training mode\cite  {chen2014dadiannao}.}}{20}{figure.1.13}}
\newlabel{fig:dadiannao_training}{{13}{20}{Comparison of energy reduction of Dadiannao against GPU in the training mode\cite {chen2014dadiannao}}{figure.1.13}{}}
\newlabel{fig:dadiannao_training@cref}{{[figure][13][]13}{20}}
\@writefile{lof}{\contentsline {figure}{\numberline {14}{\ignorespaces Comparison of energy reduction of Dadiannao against GPU in the inference mode\cite  {chen2014dadiannao}.}}{20}{figure.1.14}}
\newlabel{fig:dadiannao_inference}{{14}{20}{Comparison of energy reduction of Dadiannao against GPU in the inference mode\cite {chen2014dadiannao}}{figure.1.14}{}}
\newlabel{fig:dadiannao_inference@cref}{{[figure][14][]14}{20}}
\bibcite{domo}{1}
\bibcite{}{2}
\bibcite{borthakur2011apache}{3}
\bibcite{braam2004lustre}{4}
\bibcite{chen2014diannao}{5}
\bibcite{chen2014dadiannao}{6}
\bibcite{chilimbi2014project}{7}
\bibcite{dean2012large}{8}
\bibcite{deelman2009workflows}{9}
\bibcite{deng2009imagenet}{10}
\bibcite{ekanayake2010twister}{11}
\bibcite{esmaeilzadeh2012neural}{12}
\bibcite{farber1997parallel}{13}
\bibcite{fox2014towards}{14}
\bibcite{FrankSchmuck}{15}
\bibcite{gentzsch2001sun}{16}
\bibcite{ghemawat2003google}{17}
\bibcite{goodfellow2013maxout}{18}
\bibcite{grimshaw2013gffs}{19}
\bibcite{hinton2006fast}{20}
\bibcite{Jha2014}{21}
\bibcite{le2013building}{22}
\bibcite{luckow2012p}{23}
\bibcite{mantha2012pilot}{24}
\bibcite{plimpton2011mapreduce}{25}
\bibcite{Qiu2014}{26}
\bibcite{qiu2014towards}{27}
\bibcite{raicu2008many}{28}
\bibcite{rajasekar2010irods}{29}
\bibcite{Reed2015}{30}
\bibcite{shaun2007storage}{31}
\bibcite{shvachko2010hadoop}{32}
\bibcite{simard2003best}{33}
\bibcite{staples2006torque}{34}
\bibcite{temam2012defect}{35}
\bibcite{vavilapalli2013apache}{36}
\bibcite{yoo2003slurm}{37}
\bibcite{zaharia2012resilient}{38}
\citation{*}
